---
title: "Modos de Assistentes"
icon: "wave-pulse"
description: "Entenda os três modos de geração de voz disponíveis para seus assistentes de IA e quando usar cada um."
---

Os assistentes de IA na [MayaHub.ai](http://mayahub.ai) podem falar em três modos distintos. Cada modo determina como a fala do cliente é compreendida e como a resposta do assistente é gerada:

<Info>
  Escolher o modo certo pode melhorar o tempo de resposta, a naturalidade e a experiência geral da chamada.
</Info>

## 1. Pipeline

|                         |                                                                        | |
| ----------------------- | ---------------------------------------------------------------------- | --- |
| **Rótulo na interface** | `Pipeline`                                                             | |
| Como funciona           | Speech-to-Text → LLM → Text-to-Speech                                  | |
| **Latência**            | ~800 – 1500 ms (depende do idoma e modelo)                             | |
| Mais Indicado para      | Raciocínio complexo, prompts dinâmicos, respostas com múltiplas frases | |

O modo Pipeline primeiro transcreve as palavras do cliente em texto, processa esse texto no modelo de linguagem e depois converte a resposta de volta em áudio. É uma abordagem consolidada que oferece máxima flexibilidade:

- Suporta todas as vozes da biblioteca (incluindo vozes clonadas personalizadas).
- Lida bem com respostas longas ou em formato de parágrafo.
- Permite que o LLM insira variáveis e faça referência ao contexto anterior de forma clara.

**Quando escolher Pipeline**

- Você precisa de respostas ricas e com múltiplas frases (ex.: consultas de suporte, explicações detalhadas).
- O assistente precisa raciocinar sobre dados estruturados ou prompts complexos.
- Você prefere controle absoluto sobre a voz falada (clonada ou da marca).

## 2. Speech-to-Speech (Multimodal)

|                         |                                                            |
| ----------------------- | ---------------------------------------------------------- |
| **Rótulo na interface** | `Speech-to-speech`                                         |
| Como funciona           | Geração direta de fala para fala (sem texto intermediário) |
| **Latência**            | ~300 – 600 ms (ultra baixa)                                |
| Mais Indicado para      | Conversas naturais, respostas curtas e reativas            |

O modo Speech-to-Speech ignora a transcrição separada e o TTS. Em vez disso, usa um modelo multimodal que ouve e fala diretamente, proporcionando um fluxo mais conversacional:

- Troca de turnos rápida – os clientes recebem respostas quase instantâneas.
- Gera prosódia mais expressiva de forma nativa (entonação, pausas, fillers).
- Atualmente suporta um conjunto limitado de vozes, mas mais estão sendo adicionadas regularmente.

**Quando escolher Speech-to-Speech**

- A conversa precisa ser ágil (vendas, confirmações de reserva).
- Suas respostas são geralmente frases curtas ou confirmações rápidas.
- Você aceita as opções de voz fornecidas pelo sistema para interação mais rápida.

<Note>
  O modo Speech-to-Speech está evoluindo rapidamente. Se você precisar de uma voz clonada personalizada com baixa latência, experimente o Dualplex.
</Note>

## 3. Dualplex (Beta)

|                         |                                                                           |
| ----------------------- | ------------------------------------------------------------------------- |
| **Rótulo na interface** | `Dualplex`                                                                |
| Como funciona           | Multimodal STT + LLM (speech-to-speech) com saida ElevenLabs TTS          |
| **Latência**            | Baixa (varia conforme voz e modelo)                                       |
| Mais Indicado para      | Respostas rápidas e naturais com vozes de alta qualidade/marca (clonadas) |

O Dualplex combina a rapidez do modo Speech-to-Speech com as vozes premium e clonagem da ElevenLabs usadas no Pipeline. O assistente utiliza o modelo multimodal para entender o cliente e planejar a resposta, e depois renderiza a fala final pelo ElevenLabs, garantindo saída consistente e de alta fidelidade.

- Troca de turnos quase instantânea, semelhante ao Speech-to-Speech.
- Acesso à biblioteca de vozes ElevenLabs, incluindo vozes clonadas personalizadas.
- Excelente para respostas curtas a médias com prosódia expressiva.
- Recomendado como padrão para a maioria dos casos de uso atualmente; atualmente em Beta.

**Quando escolher Dualplex**

- Você quer respostas rápidas e naturais, mas precisa de uma voz de marca ou clonada.
- Você deseja uma entrega mais expressiva sem abrir mão da escolha precisa da voz.
- Você está confortável usando um recurso novo que ainda está em Beta.

**Mudando de modo**\
Você pode selecionar o modo para cada assistente em **Assistente → Configurações → Motor de Voz**. Teste os três modos para ver qual oferece o melhor equilíbrio entre velocidade e qualidade para seu caso de uso. O Dualplex atualmente está rotulado como Beta.

---

**Dica profissional:** Grave duas chamadas – uma em cada modo – e compare a latência percebida pelo cliente e o nível de engajamento para decidir qual se adapta melhor ao seu fluxo.